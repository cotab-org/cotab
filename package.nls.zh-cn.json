{
  "description": "这是一个VS Code扩展，是一个AI驱动的多行自动补全插件，通过完全在本地LLM上运行，旨在实现最大程度的隐私和安全性。",
  "command.toggleEnabled": "Cotab: 启用/禁用",
  "command.openSettingsEnable": "Cotab: 打开启用设置",
  "command.cancelSuggestions": "Cotab: 取消进行中的生成",
  "command.acceptSuggestion": "Cotab: 接受当前建议（所有行）",
  "command.acceptFirstLineSuggestion": "Cotab: 接受当前建议（第一行）",
  "command.clearSuggestions": "Cotab: 清除所有建议",
  "command.server.install": "Cotab: [服务器] 安装或更新 - 通过网络轻松在系统上安装/更新llama.cpp。",
  "command.server.uninstall": "Cotab: [服务器] 卸载 - 卸载系统上安装的llama.cpp",
  "command.server.start": "Cotab: [服务器] 启动 - 启动系统上的llama-server",
  "command.server.stop": "Cotab: [服务器] 停止 - 停止系统上的llama-server",
  "command.menu.clickstatusbar": "Cotab: [菜单] 如果不点击而悬停，菜单将出现！",
  "config.basic.enabled": "启用/禁用自动补全",
  "config.basic.disableForExtensions": "对扩展禁用自动补全（文件扩展名的逗号分隔列表。例如 'txt,json'）",
  "config.basic.autoStart": "扩展激活时自动启动服务器。cotab.llm.apiBaseURL设置必须为空。",
  "config.basic.autoStopOnIdleTime": "自动停止服务器之前的空闲超时（秒）",
  "config.basic.commentLanguage": "注释语言。如果为空，则使用操作系统语言（例如 'English', '日本語', '简体中文', 'Français'）",
  "config.basic.selectedPromptMode": "使用的提示设置模式。如果为空，则使用默认编码提示",
  "config.llm.llamaCppVersion": "已安装的llama.cpp（llama-server）版本。（Custom: customLlamaCppVersion）",
  "config.llm.customLlamaCppVersion": "llama.cpp（llama-server）的自定义版本。例如 'b7010'（仅在llamaCppVersion为Custom时使用）",
  "config.llm.provider": "要使用的LLM提供商",
  "config.llm.apiBaseURL": "OpenAI兼容的基础URL（例如 `http://localhost:8080/v1`）推荐llama-server（如果使用自动启动本地服务器，请留空。）",
  "config.llm.apiKey": "用作OpenAI兼容服务器的Bearer令牌的API密钥（可选。您可以留空。）",
  "config.llm.localServerPreset": "本地服务器（llama.cpp）的预设参数。VRAM使用量估计是针对上下文大小32k的。",
  "config.llm.localServerPreset.enum.0": "模型:Qwen3-4B-Instruct-2507\n\n-hf unsloth/Qwen3-4B-Instruct-2507-GGUF --temp 0.7 --top-p 0.8 --top-k 20 --min-p 0.01 --repeat-penalty 1.05 --jinja -fa on -ngl 999 -kvu -ctk q8_0 -ctv q8_0",
  "config.llm.localServerPreset.enum.1": "模型:Qwen3-Coder-30B-A3B-Instruct-UD-IQ2_M\n\n-hf unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF:Qwen3-Coder-30B-A3B-Instruct-UD-IQ2_M --temp 0.7 --top-p 0.8 --top-k 20 --min-p 0.01 --repeat-penalty 1.05 --jinja -fa on -ngl 999 -kvu --n-cpu-moe 35",
  "config.llm.localServerPreset.enum.2": "模型:Qwen3-Coder-30B-A3B-Instruct-UD-IQ2_M\n\n-hf unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF:Qwen3-Coder-30B-A3B-Instruct-UD-IQ2_M --temp 0.7 --top-p 0.8 --top-k 20 --min-p 0.01 --repeat-penalty 1.05 --jinja -fa on -ngl 999 -kvu --n-cpu-moe 11",
  "config.llm.localServerPreset.enum.3": "模型:Qwen3-Coder-30B-A3B-Instruct-UD-IQ2_M\n\n-hf unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF:Qwen3-Coder-30B-A3B-Instruct-UD-IQ2_M --temp 0.7 --top-p 0.8 --top-k 20 --min-p 0.01 --repeat-penalty 1.05 --jinja -fa on -ngl 999 -kvu",
  "config.llm.localServerPreset.enum.4": "模型:Qwen3-Coder-30B-A3B-Instruct-UD-Q4_K_XL\n\n-hf unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF:Qwen3-Coder-30B-A3B-Instruct-UD-Q4_K_XL --temp 0.7 --top-p 0.8 --top-k 20 --min-p 0.01 --repeat-penalty 1.05 --jinja -fa on -ngl 999 -kvu",
  "config.llm.localServerPreset.enum.5": "使用cotab.llm.localServerCustom进行自定义设置",
  "config.llm.localServerCustom": "启动本地服务器（llama.cpp）的参数",
  "config.llm.localServerPort": "本地服务器（llama.cpp）的端口",
  "config.llm.localServerContextSize": "本地服务器（llama.cpp）的上下文大小",
  "config.llm.localServerCacheRam": "本地服务器（llama.cpp）的最大RAM备份缓存大小（MiB）（-1 - 无限制，0 - 禁用） https://github.com/ggml-org/llama.cpp/pull/16391",
  "config.llm.model": "要使用的远程模型名称",
  "config.llm.temperature": "创造性（0-1，建议使用较低值。如果为-1，则使用服务器的默认设置）",
  "config.llm.top_p": "Top-p采样（如果为-1，则使用服务器的默认设置）",
  "config.llm.top_k": "Top-k采样（如果为-1，则使用服务器的默认设置）",
  "config.llm.maxTokens": "LLM输出的最大令牌数",
  "config.llm.maxOutputLines": "LLM的最大输出行数",
  "config.llm.timeoutMs": "LLM调用超时（毫秒）",
  "config.prompt.additionalSystemPrompt": "添加到默认系统提示的附加提示",
  "config.prompt.additionalUserPrompt": "添加到默认用户提示的附加提示",
  "config.prompt.additionalAssistantThinkPrompt": "添加到默认助手思考提示的附加提示",
  "config.prompt.additionalAssistantOutputPrompt": "添加到默认助手输出提示的附加提示",
  "config.promptDetail.startEditingHereSymbol": "指示编辑开始的符号字符串",
  "config.promptDetail.stopEditingHereSymbol": "指示编辑结束的符号字符串",
  "config.promptDetail.completeHereSymbol": "代码补全期间插入的符号字符串",
  "config.promptDetail.aroundBeforeLines": "在光标位置之前检索的行数（LLM推理目标范围）\n推荐: 0\n（设置为0使LLM输出从光标行开始，稳定LLM输出）",
  "config.promptDetail.aroundAfterLines": "在光标位置之后检索的行数（编辑目标范围）",
  "config.promptDetail.aroundMergeAfterLines": "合并期间使用的周围代码的结束行（编辑目标范围）\n推荐: cotab.promptDetail.aroundAfterLines + LLM输出行（约10行）+ 约5行",
  "config.promptDetail.aroundCacheBeforeLines": "用于缓存利用的周围代码的起始行。\n如果光标位置不超过此行，则不会更新用户提示中的源代码，从而启用有效的提示缓存使用。",
  "config.promptDetail.aroundCacheAfterLines": "用于缓存利用的周围代码的结束行。\n如果光标位置不超过此行，则不会更新用户提示中的源代码，从而启用有效的提示缓存使用。",
  "config.promptDetail.aroundLatestAddBeforeLines": "用于最新利用的周围代码的起始行。\n最终最新行是aroundBeforeLines + aroundLatestAddBeforeLines",
  "config.promptDetail.aroundLatestAddAfterLines": "用于最新利用的周围代码的结束行。\n最终最新行是aroundAfterLines + aroundLatestAddAfterLines",
  "config.promptDetail.maxSymbolCharNum": "要包含在符号代码块中的符号的最大字符数。\n大约1000个字符允许20个符号输入。\n在Qwen3:4b-Instruct-2507中，大约1000个字符使用约250个令牌。",
  "config.promptDetail.enableCodeSummary": "启用源代码摘要功能。\n如果启用，源代码将被摘要并包含在提示中。",
  "config.detail.logLevel": "日志输出级别（ERROR: 仅错误，WARNING: 警告及以上，INFO: 信息及以上，DEBUG: 全部）",
  "config.ui.showProgressSpinner": "完成代码补全时显示旋转图标",
  "config.gettingStarted.hideOnStartup": "下次启动时不显示入门视图"
}

