{
  "gettingStarted.title": "Cotab クイックスタート",
  "gettingStarted.gettingStarted": "クイックスタート",
  "gettingStarted.setupServer": "サーバーセットアップ",
  "gettingStarted.preset": "プリセット",
  "gettingStarted.showAllPresets": "全プリセット表示",
  "gettingStarted.presetTooltip": "llama-serverの起動引数のプリセットです。細かい調整をする場合は、Customを選んでください。",
  "gettingStarted.aboutAvailableModels": "利用モデルについて",
  "gettingStarted.aboutRemoteServers": "リモートサーバーについて",
  "gettingStarted.customArgsPlaceholder": "llama-server引数を入力",
  "gettingStarted.contextSize": "コンテキストサイズ",
  "gettingStarted.contextSizeTooltip": "必須:\n - 16k (16384) 以上を設定してください。\n\n推奨:\n - 32k (32768) 以上を設定してください。\n\n理由:\n - システムプロンプトは約5kを使用し、1,000行のコードはさらに約12kを使用します。\n - そのため、コンテキストウィンドウを20k (20480) 以上に設定してください。\n\nデフォルトモデル (Qwen3-4B-Instruct-2507) のVRAM使用量:\n - 16k: 約4 GB\n - 32k: 約5.5 GB",
  "gettingStarted.or": "または",
  "gettingStarted.apiBaseURL": "OpenAI互換のベースURL",
  "gettingStarted.apiBaseURLTooltip": "ローカルサーバーの自動起動を使用する場合は、空白のままにしてください。",
  "gettingStarted.apiKey": "APIキー",
  "gettingStarted.model": "モデル",
  "gettingStarted.modelTooltip": "サーバーで利用できるモデル名。",
  "gettingStarted.letsGetAutocompleting": "自動補完を始めましょう！",
  "gettingStarted.command": "コマンド",
  "gettingStarted.keybinding": "キーバインド",
  "gettingStarted.acceptAll": "すべて受け入れ",
  "gettingStarted.acceptFirstLine": "最初の行を受け入れ",
  "gettingStarted.reject": "拒否",
  "gettingStarted.rejectNote": "補足: 拒否することで、次の補完候補を変更できます。",
  "gettingStarted.showThisPageAgain": "このページの表示方法",
  "gettingStarted.hoverStatusBar": "ステータスバーにホバーしてください。クリックしないでください！",
  "gettingStarted.dontShowAgain": "次回から表示しない",
  "gettingStarted.learnMore": "詳細情報",
  "gettingStarted.progressIconDescription": "進捗アイコンの説明",
  "gettingStarted.analyzing": "分析中",
  "gettingStarted.completingCurrentLine": "現在の行を<br>補完中",
  "gettingStarted.completingAfterCurrentLine": "現在の行以降を<br>補完中",
  "gettingStarted.showProgressIcon": "進捗アイコンを表示",
  "gettingStarted.detailSettings": "詳細設定",
  "gettingStarted.commentLanguage": "コメント言語",
  "gettingStarted.commentLanguageTooltip": "コード内コメントの言語です。",
  "gettingStarted.commentLanguageExample": "(例: 'English', '日本語', '简体中文', 'Français')",
  "gettingStarted.showOnSuggestConflict": "VS Codeのインラインサジェスト表示を使用",
  "gettingStarted.showOnSuggestConflictTooltip": "VS Codeのインラインサジェスト機能を快適に使用するにはエディタ設定の変更が必要なため、このオプションはデフォルトで無効です。",
  "gettingStarted.showOnSuggestConflictHelperText": "有効にすると「showOnSuggestConflict」設定が「always」に設定されます。",
  "gettingStarted.inlineSuggestionDisplayDefaultLabel": "デフォルト",
  "gettingStarted.inlineSuggestionDisplaySystemLabel": "VS Codeのシステム表示を使用",
  "gettingStarted.inlineSuggestionDisplayNote": "VS Code のシステムインライン表示を使用すると、補完リストと一緒に表示されない場合があります。",
  "gettingStarted.openSettings": "設定を開く",
  "gettingStarted.openSettingsTooltip": "Cotab設定を開く",
  "gettingStarted.server.stop": "サーバーを停止",
  "gettingStarted.server.network": "ネットワークサーバー接続中",
  "gettingStarted.server.start": "サーバーを起動",
  "gettingStarted.server.install": "サーバーをインストール",
  "gettingStarted.server.unsupported": "インストール非対応",
  "gettingStarted.server.autoStartTooltip": "自動起動を使用する場合、「OpenAI互換のベースURL」設定は空白である必要があります。",
  "gettingStarted.saveError": "設定の保存に失敗しました: {0}",
  "menuIndicator.codeCompletions": "コード補完",
  "menuIndicator.enableGlobally": "全体で有効化",
  "menuIndicator.enableFor": "{0} で有効化",
  "menuIndicator.installingServer": "サーバー（llama.cpp）をインストール中 ...",
  "menuIndicator.serverAlreadyInstalled": "サーバー（llama.cpp）は既にインストールされています。更新しますか？",
  "menuIndicator.yes": "はい",
  "menuIndicator.no": "いいえ",
  "menuIndicator.serverInstallFailed": "サーバー（llama.cpp）のインストールに失敗しました: {0}",
  "menuIndicator.serverNotInstalled": "サーバー（llama.cpp）がインストールされていません",
  "menuIndicator.reallyUninstallServer": "本当にサーバー（llama.cpp）をアンインストールしますか？",
  "menuIndicator.uninstallingServer": "サーバー（llama.cpp）をアンインストール中 ...",
  "menuIndicator.serverUninstalled": "サーバー（llama.cpp）をアンインストールしました",
  "menuIndicator.serverUninstallFailed": "サーバー（llama.cpp）のアンインストールに失敗しました: {0}",
  "menuIndicator.serverAlreadyRunning": "ローカルサーバーは既に実行中です。再起動しますか？",
  "menuIndicator.startServer": "llama-serverを開始",
  "menuIndicator.stopServer": "llama-serverを停止",
  "menuIndicator.promptMode.Coding": "コーディング",
  "menuIndicator.promptMode.Comment": "コメント",
  "menuIndicator.promptMode.Translate": "翻訳",
  "menuIndicator.promptMode.Proofreading(experimental)": "文章校正（実験的）",
  "menuIndicator.promptMode.BusinessChat(experimental)": "ビジネスチャット校正（実験的）",
  "terminalCommand.installNotSupported": "自動インストール/アップグレードは現在MacとWindowsのみサポートされています。llama.cppパッケージを手動でダウンロードし、フォルダーをパスに追加してください。詳細については github.com/ggml-org/llama.vscode/wiki を参照してください。",
  "terminalCommand.uninstallNotSupported": "自動アンインストールは現在MacとWindowsのみサポートされています。llama.cppを手動でアンインストールしてください。詳細については github.com/ggml-org/llama.vscode/wiki を参照してください。"
}

